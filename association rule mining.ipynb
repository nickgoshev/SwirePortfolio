{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87781d0",
   "metadata": {},
   "source": [
    "### Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabaf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from google.colab import drive, auth\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from google.colab import drive\n",
    "from google.colab import auth\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23803d29",
   "metadata": {},
   "source": [
    "### Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ae677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "master_df = pd.read_csv('IWC_Work_Orders_Extract.csv')\n",
    "\n",
    "# GROUP 2: Nick S., Nick G.\n",
    "master_df2 = master_df.copy()\n",
    "\n",
    "\n",
    "columns_to_remove = ['ORDER_ID', 'FUNCTIONAL_AREA_NODE_1_MODIFIED',\n",
    "                    'FUNCTIONAL_AREA_NODE_2_MODIFIED', 'FUNCTIONAL_AREA_NODE_3_MODIFIED',\n",
    "                    'FUNCTIONAL_AREA_NODE_4_MODIFIED', 'FUNCTIONAL_AREA_NODE_5_MODIFIED',\n",
    "                     'EQUIP_VALID_TO', 'PRODUCTION_LOCATION']\n",
    "\n",
    "master_df2 = master_df2.drop(columns=columns_to_remove, axis=1)\n",
    "\n",
    "\n",
    "columns_to_fill = ['MAINTENANCE_PLAN', 'MAINTENANCE_ITEM', 'FUNCTIONAL_LOC', 'EQUIPMENT_DESC', 'EQUIP_CAT_DESC',\n",
    "                  'EQUIP_START_UP_DATE', 'EQUIP_VALID_FROM', 'EQUIPMENT_ID']\n",
    "master_df2[columns_to_fill] = master_df[columns_to_fill].fillna('Unknown')\n",
    "\n",
    "planned_df = master_df2[master_df2['MAINTENANCE_ACTIVITY_TYPE'] == 'Planned']\n",
    "\n",
    "\n",
    "columns_to_drop = ['EXECUTION_START_DATE', 'EXECUTION_FINISH_DATE',\n",
    "                   'ACTUAL_START_TIME', 'ACTUAL_FINISH_TIME', 'EQUIP_VALID_FROM',\n",
    "                   'EQUIP_START_UP_DATE', 'MAINTENANCE_PLAN', 'MAINTENANCE_ITEM', 'ACTUAL_WORK_IN_MINUTES']\n",
    "planned_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f64d442",
   "metadata": {},
   "source": [
    "### Planned Association Rule Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with 'Unknown' in any column\n",
    "planned_df_no_unknown = planned_df[~planned_df.apply(lambda row: row.astype(str).str.contains('Unknown')).any(axis=1)]\n",
    "\n",
    "# Create transactions for association rule mining, ensuring all elements are strings\n",
    "transactions = planned_df_no_unknown[['FUNCTIONAL_LOC', 'ORDER_DESCRIPTION', 'MAINTENANCE_ACTIVITY_TYPE']].astype(str).values.tolist()\n",
    "\n",
    "# Encode transactions and apply apriori\n",
    "te = TransactionEncoder()\n",
    "df = pd.DataFrame(te.fit_transform(transactions), columns=te.columns_)\n",
    "frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Generate and display rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a608e0a",
   "metadata": {},
   "source": [
    "The above rules show the relationship between ORDER_DESCRIPTION, MAINTENANCE_PLAN, and FUNCTIONAL_LOC. We can see how the different values for each attribute show up in relation to one another and we can estimate their relationships based on that. For example, the two highest lift rules are 000000022943 -> E-STOP FOR ELEC MONTHLY SHUTDOWN and its inverse. The confidence of the latter is 100% indicating that whenever there is an emergency stop for monthly shutdown that specified maintenence plan is always used. However if we look at the first rule it does not have 100% confidence indicating that it also has other uses. Other things we can observe in these rules are which production locations are linked to which rules or maintenence plans.There are also rules that contain combinations of the other attributes as both antecedents and consequents indicating strong relationships between for example a certain order desc and maintenence plan with a specific factory location."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
